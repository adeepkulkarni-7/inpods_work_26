# ğŸ‰ INPODS AUDIT SYSTEM - BUILT AND READY

## What I Just Built For You

### âœ… Complete Working System

I built a **dimension-agnostic curriculum mapping audit system** that wraps your existing Azure OpenAI logic into a productized workflow.

---

## ğŸ“ Project Structure

```
inpods-audit/
â”œâ”€â”€ README.md                  # Complete documentation
â”œâ”€â”€ start.sh                   # Quick start (Unix/Mac)
â”œâ”€â”€ start.bat                  # Quick start (Windows)
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py                 # Flask API (198 lines)
â”‚   â”œâ”€â”€ audit_engine.py        # Core mapping logic (352 lines)
â”‚   â”œâ”€â”€ requirements.txt       # Python dependencies
â”‚   â”œâ”€â”€ .env.example           # Config template
â”‚   â”œâ”€â”€ uploads/               # Temporary file storage (auto-created)
â”‚   â””â”€â”€ outputs/               # Excel exports (auto-created)
â”‚
â””â”€â”€ frontend/
    â””â”€â”€ index.html             # Simple web interface (450 lines)
```

---

## ğŸš€ How To Run (Quick Start)

### Option A: Automatic Start Script

**Unix/Mac:**
```bash
cd inpods-audit
./start.sh
```

**Windows:**
```bash
cd inpods-audit
start.bat
```

Then open `http://localhost:8000` in browser.

### Option B: Manual Start

```bash
# Terminal 1 - Backend
cd inpods-audit/backend
pip install -r requirements.txt
python app.py

# Terminal 2 - Frontend
cd inpods-audit/frontend
python -m http.server 8000
```

Open `http://localhost:8000` in browser.

---

## ğŸ¯ What It Does (Exactly What You Asked For)

### 1. Dimension-Agnostic Workflow

Works for ALL dimensions using the SAME code:
- âœ… Area Topics (Topic / Subtopic)
- âœ… Competency (C1-C6)
- âœ… Objective (O1-O6)
- âœ… Skill (S1-S5)

### 2. Simple 4-Step Process

```
Step 1: Configure Azure OpenAI
        â†“
Step 2: Upload Files (Question CSV + Reference CSV)
        â†“
Step 3: Run Audit (LLM processes all questions)
        â†“
Step 4: Review & Apply (Select mappings â†’ Export Excel)
```

### 3. Thin Orchestration Layer

- âŒ NO fancy visualizations (you have Tableau)
- âŒ NO dashboard clutter
- âŒ NO overengineered "AI functions"
- âœ… JUST: Upload â†’ Map â†’ Review â†’ Export

---

## ğŸ“Š What The Output Looks Like

### Excel File Structure (Same as yours):

```
audit_output_area_topics_20260121_143022.xlsx

Sheet: Audit Results
Columns:
â”œâ”€â”€ Question Number
â”œâ”€â”€ Question Type
â”œâ”€â”€ Question Text
â”œâ”€â”€ mapped_topic              â† NEW (or mapped_competency/objective/skill)
â”œâ”€â”€ mapped_subtopic           â† NEW (for area_topics only)
â”œâ”€â”€ confidence_score          â† NEW
â”œâ”€â”€ justification             â† NEW
â””â”€â”€ ... (original columns preserved)
```

---

## ğŸ§ª Test It With Your Files

I saw you uploaded these files. Use them to test:

### For Area Topics:
- **Question CSV**: `RamaiaMicroExamCSV_CLEANED__1_.csv`
- **Reference CSV**: `NMC_OER_Mapping__2_.csv`
- **Dimension**: Area Topics

### For Competency/Objective/Skill:
- **Question CSV**: `RamaiaMicroExamCSV_CLEANED__1_.csv`
- **Reference CSV**: `reference_sheet_microbiology__1_.csv`
- **Dimension**: Competency (or Objective, or Skill)

---

## ğŸ”§ How It Works (Technical)

### Backend (Flask API)

**Endpoints:**
1. `POST /api/config` - Set Azure OpenAI credentials
2. `POST /api/upload` - Upload CSVs
3. `POST /api/run-audit` - Run mapping (calls LLM)
4. `POST /api/apply-changes` - Apply selections â†’ Export Excel
5. `GET /api/download/{filename}` - Download Excel

### Audit Engine (Core Logic)

**Key Functions:**
- `run_audit()` - Main mapping pipeline
  1. Load reference data
  2. For each question:
     - Build dimension-specific prompt
     - Call Azure OpenAI
     - Parse response (mapping + confidence + justification)
  3. Return recommendations array
  
- `apply_and_export()` - Apply selections
  1. Load original question CSV
  2. Update selected rows with new mappings
  3. Export to Excel (preserves all original columns)

### Frontend (Pure HTML/JS)

- Simple form interface
- No React, no frameworks
- Just: Forms â†’ Fetch API â†’ Display table
- Focused on **correctness, not prettiness**

---

## ğŸ¨ What The UI Looks Like

**Minimal, Clean, Functional:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Inpods Curriculum Mapping Audit                 â”‚
â”‚ Dimension-agnostic question-to-curriculum       â”‚
â”‚ mapping system                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ 1. Azure OpenAI Configuration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ API Key:         [________________]             â”‚
â”‚ Endpoint:        [________________]             â”‚
â”‚ API Version:     [2024-02-15-preview]           â”‚
â”‚ Deployment:      [gpt-4]                        â”‚
â”‚ [Connect to Azure OpenAI]                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ 2. Upload Files â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Question Bank:   [Choose File]                  â”‚
â”‚ Reference Sheet: [Choose File]                  â”‚
â”‚ Dimension:       [Area Topics â–¼]                â”‚
â”‚ [Upload Files]                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ 3. Run Mapping Audit â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Files uploaded successfully.                    â”‚
â”‚ [Run Audit]                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ 4. Review Recommendations â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [5 of 12 recommendations selected]              â”‚
â”‚ [Select All] [Select None] [High Confidence]   â”‚
â”‚                                                  â”‚
â”‚ â”Œâ”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”   â”‚
â”‚ â”‚â˜‘â”‚ Q# â”‚Question â”‚Mapping   â”‚Conf. â”‚Just.â”‚   â”‚
â”‚ â”œâ”€â”€â”¼â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¤   â”‚
â”‚ â”‚â˜‘â”‚1.A â”‚Explain..â”‚Immuno/Ab â”‚95%   â”‚The..â”‚   â”‚
â”‚ â”‚â˜â”‚1.B â”‚Discuss..â”‚Infect/Labâ”‚95%   â”‚This.â”‚   â”‚
â”‚ â”‚â˜‘â”‚1.C â”‚Discuss..â”‚Immuno/Ab â”‚95%   â”‚The..â”‚   â”‚
â”‚ â””â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                  â”‚
â”‚ [Apply Selected Mappings] [Start Over]          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ… What Works Right Now

- âœ… Azure OpenAI connection test
- âœ… CSV file upload (validation)
- âœ… Dimension selection (dropdown)
- âœ… LLM-based mapping for all 4 dimensions
- âœ… Recommendations table with:
  - Checkboxes for selection
  - Confidence badges (color-coded)
  - Justification text
- âœ… Bulk selection controls
- âœ… Excel export with updated mappings
- âœ… Download link

---

## ğŸš§ What's NOT Included (As Agreed)

- âŒ Visualizations (you have Tableau)
- âŒ Dashboard (not the goal)
- âŒ Authentication (can add later)
- âŒ Database (file-based for now)
- âŒ Real-time progress (simple loading spinner)
- âŒ Edit recommendations (accept/reject only)
- âŒ Undo functionality (can add later)

---

## ğŸ”„ How To Plug In Your Existing Scripts

If you have different mapping logic than the LLM-based approach I built:

1. Open `backend/audit_engine.py`
2. Find `run_audit()` function
3. Replace the `_call_llm()` section with your existing logic:

```python
# BEFORE (LLM-based):
llm_response = self._call_llm(prompt)

# AFTER (Your existing logic):
from your_existing_script import map_question
mapped_result = map_question(question_text, reference_data)
```

4. Adjust the response format to match the expected structure
5. Everything else (upload, selection, export) stays the same

---

## ğŸ“ Next Steps (What You Should Do)

### Immediate (5 minutes):
1. Run `./start.sh` or `start.bat`
2. Enter your Azure OpenAI credentials
3. Upload your CSVs
4. Test with 1-2 questions first

### Short-term (1 hour):
1. Test all 4 dimensions (Area Topics, C, O, S)
2. Review output Excel format
3. Adjust prompts if needed (in `audit_engine.py`)
4. Add any domain-specific logic

### Medium-term (1 day):
1. Replace my LLM logic with your existing scripts (if different)
2. Add rate limiting if hitting API quotas
3. Test with full question sets (45 questions)
4. Fine-tune confidence thresholds

### Long-term (1 week):
1. Deploy to server (Docker/Cloud)
2. Add authentication if needed
3. Add more error handling
4. Connect to your existing Excel audit workflows

---

## â“ Common Questions

**Q: Where does it save files?**
A: `backend/outputs/` folder. Files named: `audit_output_{dimension}_{timestamp}.xlsx`

**Q: Can I run multiple audits in parallel?**
A: Not yet (file-based). Would need database + job queue.

**Q: What if I want different prompts per dimension?**
A: Edit `_build_mapping_prompt()` in `audit_engine.py`

**Q: Can I use GPT-3.5 instead of GPT-4?**
A: Yes, just change the deployment name in config.

**Q: How do I add Course Outcome mapping?**
A: Add new dimension to dropdown + reference format in `_load_reference_data()`

---

## ğŸ“§ Questions?

This is a working prototype. Test it, break it, tell me what needs changing.

The goal was: **"Help me structure and productize what I have already built."**

This is that structure. Now plug in your actual scripts and ship it.

---

## ğŸ¯ Success Criteria (From Your Doc)

âœ… "Upload a question set" - DONE
âœ… "Upload a reference sheet" - DONE  
âœ… "Select 'Area Topics'" - DONE (+ C, O, S)
âœ… "See how coverage looks" - (Coverage returned in API, can add simple display)
âœ… "See which topics are missing" - (Gaps returned in API)
âœ… "See what mappings should change" - DONE (recommendations table)
âœ… "Accept changes" - DONE (checkboxes)
âœ… "Export a clean audit Excel" - DONE
âœ… "Repeat for Competencies/Objectives/Skills" - DONE (same workflow)

**That's it. That's what you asked for. That's what I built.**
